{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "'''Main'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time\n",
    "import pickle, gzip\n",
    "\n",
    "'''Data Viz'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "'''Data Prep and Model Evaluation'''\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Data\n",
    "current_path = os.getcwd()\n",
    "#file = os.path.sep.join(['', 'datasets', 'credit_card_data', 'credit_card.csv'])\n",
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fraudulent transactions: 492\n"
     ]
    }
   ],
   "source": [
    "# Count total fraud\n",
    "print(\"Number of fraudulent transactions:\", data['Class'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# Split to train and test and scale features\n",
    "dataX = data.drop(['Class'],axis=1)\n",
    "dataY = data.loc[:,'Class'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(dataX, dataY, test_size=0.33, \\\n",
    "                    random_state=2018, stratify=dataY)\n",
    "    \n",
    "featuresToScale = X_train.columns\n",
    "sX = pp.StandardScaler(copy=True)\n",
    "X_train.loc[:,featuresToScale] = sX.fit_transform(X_train.loc[:,featuresToScale])\n",
    "X_test.loc[:,featuresToScale] = sX.transform(X_test.loc[:,featuresToScale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate reconstruction error\n",
    "def anomalyScores(originalDF, reducedDF):\n",
    "    loss = np.sum((np.array(originalDF)-np.array(reducedDF))**2, axis=1)\n",
    "    loss = pd.Series(data=loss,index=originalDF.index)\n",
    "    loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "def plotResults(trueLabels, anomalyScores, returnPreds = False):\n",
    "    preds = pd.concat([trueLabels, anomalyScores], axis=1)\n",
    "    preds.columns = ['trueLabel', 'anomalyScore']\n",
    "    precision, recall, thresholds = \\\n",
    "        precision_recall_curve(preds['trueLabel'],preds['anomalyScore'])\n",
    "    average_precision = \\\n",
    "        average_precision_score(preds['trueLabel'],preds['anomalyScore'])\n",
    "    \n",
    "    plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    \n",
    "    plt.title('Precision-Recall curve: Average Precision = \\\n",
    "    {0:0.2f}'.format(average_precision))\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(preds['trueLabel'], \\\n",
    "                                     preds['anomalyScore'])\n",
    "    areaUnderROC = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic: \\\n",
    "    Area under the curve = {0:0.2f}'.format(areaUnderROC))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    if returnPreds==True:\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View scatterplot\n",
    "def scatterPlot(xDF, yDF, algoName):\n",
    "    tempDF = pd.DataFrame(data=xDF.loc[:,0:1], index=xDF.index)\n",
    "    tempDF = pd.concat((tempDF,yDF), axis=1, join=\"inner\")\n",
    "    tempDF.columns = [\"First Vector\", \"Second Vector\", \"Label\"]\n",
    "    sns.lmplot(x=\"First Vector\", y=\"Second Vector\", hue=\"Label\", \\\n",
    "               data=tempDF, fit_reg=False)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(\"Separation of Observations using \"+algoName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
